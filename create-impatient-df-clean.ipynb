{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Inpatient Dataframe\n",
    "\n",
    "This code takes a directory and regex expression for filename to import all relevant synthetic data files and attaches summary information by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import fnmatch\n",
    "from datetime import datetime\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## alternate way to gather files matching a certain fname\n",
    "def list_files(directory, pattern):\n",
    "    all_files = os.listdir(directory) \n",
    "    relevant_files = []\n",
    "    for entry in all_files:  \n",
    "        if fnmatch.fnmatch(entry, pattern):\n",
    "            #print (entry)\n",
    "            relevant_files.append(entry)\n",
    "    return relevant_files\n",
    "## bring in all inpatient files from synthetic_data folder\n",
    "def read_in_all_files(parent_folder, pattern):\n",
    "    inpatient_files = list_files(parent_folder, pattern)\n",
    "    df = pd.DataFrame()\n",
    "    for d in inpatient_files:\n",
    "        temp_df = pd.read_csv(parent_folder + d , compression='zip')\n",
    "        temp_df['sample_number'] = re.sub('\\.','',re.findall('\\d{1}\\.', d)[0])\n",
    "        df = pd.concat([df, temp_df], axis = 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper functions\n",
    "def grouping_helper(x, keep_list):\n",
    "    if x in keep_list:\n",
    "        x = re.sub('[^A-Za-z0-9]+','',x).lower()\n",
    "    else:\n",
    "        x = 'Other'\n",
    "    return x\n",
    "\n",
    "def join_codes(row):\n",
    "    return \" \".join(list(set([str(v) for i, v in row.iteritems() if pd.notnull(v)])))\n",
    "\n",
    "def join_group_codes(row):\n",
    "    return \" \".join(list(set([str(v)[0:3] for i, v in row.iteritems() if pd.notnull(v)])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean and create core dataset\n",
    "def create_inpatient_core_df(df):\n",
    "    print(df.columns)\n",
    "    df.columns = [c.lower() for c in df.columns]\n",
    "    df = df.loc[(df['clm_from_dt'].notnull() & df['clm_thru_dt'].notnull()),:]\n",
    "\n",
    "    df['clm_from_datetime'] = [datetime.strptime(str(int(a)),'%Y%m%d') for a in df['clm_from_dt']]\n",
    "    df['clm_thru_datetime'] = [datetime.strptime(str(int(a)),'%Y%m%d') for a in df['clm_thru_dt']]\n",
    "    df['clm_start_year'] = df['clm_from_datetime'].dt.year\n",
    "    df['clm_start_month'] = df['clm_from_datetime'].dt.month\n",
    "\n",
    "    condition_list = [df['clm_utlztn_day_cnt'] <= 3,\n",
    "                      (df['clm_utlztn_day_cnt'] > 3) & (df['clm_utlztn_day_cnt'] <= 7),\n",
    "                      df['clm_utlztn_day_cnt'] > 7]\n",
    "    choice_list = ['0-3 days', '4-7 days', 'Over 7 days']\n",
    "    df['clm_utlztn_day_cnt_grouped'] = np.select(condition_list, choice_list, default = 'Other')\n",
    "\n",
    "    # keep these key columns \n",
    "    claims_data_key_cols = ['clm_id','desynpuf_id','sample_number','clm_start_year',\n",
    "                           'clm_start_month','clm_from_datetime',\n",
    "                            'clm_utlztn_day_cnt','clm_utlztn_day_cnt_grouped',\n",
    "                            'prvdr_num','prvdr_num_grp','at_physn_npi','clm_drg_cd',\n",
    "                            'clm_drg_cd_grp','clm_pmt_amt']\n",
    "\n",
    "    # group major diagnosis codes\n",
    "    keep_list = df.clm_drg_cd.value_counts().index[df.clm_drg_cd.value_counts().values > 100]\n",
    "    df['clm_drg_cd_grp'] = [grouping_helper(r, keep_list) for r in df.clm_drg_cd]\n",
    "    #df.clm_drg_cd_grp.value_counts()\n",
    "    keep_list_prvdr = df.prvdr_num.value_counts().index[df.prvdr_num.value_counts().values > 100]\n",
    "    df['prvdr_num_grp'] = [grouping_helper(r, keep_list_prvdr) for r in df.prvdr_num]\n",
    "\n",
    "\n",
    "    icd9_dgns_cols = [d for d in df.columns if d[:9] == ('icd9_dgns')]\n",
    "    icd9_prcdr_cols = [p for p in df.columns if p[:10] == ('icd9_prcdr')]\n",
    "    hcpcs_cols = [h for h in df.columns if h[:8] == ('hcpcs_cd')]\n",
    "    provider_cols = [pv for pv in df.columns if 'physn_npi' in pv] \n",
    "\n",
    "    collapse_columns_list = [icd9_dgns_cols, icd9_prcdr_cols, \n",
    "                             hcpcs_cols, provider_cols]\n",
    "    suffix_list = ['icd9_dgns','icd9_pcrdr','hcpcs_cd','physn_npi']\n",
    "\n",
    "    core_df = df.loc[:,claims_data_key_cols]\n",
    "    print(core_df.head())\n",
    "    i = 0\n",
    "    for i in range(len(collapse_columns_list)):\n",
    "        print(suffix_list[i])\n",
    "        print(collapse_columns_list[i])\n",
    "        \n",
    "        # create collapsed codes\n",
    "        collapsed_codes = df.loc[:, collapse_columns_list[i]].apply(join_codes, axis = 1)\n",
    "        core_df['collapsed_' + suffix_list[i]] = collapsed_codes\n",
    "    \n",
    "    # try and group icd9 dgns\n",
    "    collapsed_icd9_dgns_group_codes = df.loc[:, icd9_dgns_cols].apply(join_group_codes, axis = 1)\n",
    "    core_df['collapsed_icd9_dgns_group'] = collapsed_icd9_dgns_group_codes\n",
    "\n",
    "    # try and group icd9 prcdr\n",
    "    collapsed_icd9_prcdr_group_codes = df.loc[:, icd9_prcdr_cols].apply(join_group_codes, axis = 1)\n",
    "    core_df['collapsed_icd9_prcdr_group'] = collapsed_icd9_prcdr_group_codes\n",
    "        \n",
    "        ## only need to uncomment if using original df as core_df\n",
    "        #df.drop(columns = collapse_columns_list[i], inplace = True)\n",
    "    \n",
    "    return core_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create keys master list\n",
    "def add_summary_info(df):\n",
    "    filelist = list_files(directory = 'C:/Users/598300/wids/medicare-fraud/synthetic_data/', \n",
    "                          pattern = '*_Beneficiary_Summary_File_Sample_*')\n",
    "    file_dict = dict(zip(filelist,[re.sub('\\.','',re.findall('\\d{1}\\.', d)[0]) for d in filelist])) \n",
    "    print(file_dict)\n",
    "    \n",
    "    # gather and deduplicate key columns from all summary files\n",
    "    k = pd.DataFrame(columns = ['desynpuf_id','bene_birth_dt', 'bene_sex_ident_cd', 'bene_race_cd', 'sample_number'])\n",
    "    for sf in filelist:\n",
    "        raw_df = pd.read_csv('synthetic_data/'+ sf , compression='zip')\n",
    "        f = pd.DataFrame({'desynpuf_id' : raw_df['DESYNPUF_ID'],\n",
    "                          'bene_birth_dt' : raw_df['BENE_BIRTH_DT'], \n",
    "                          'bene_sex_ident_cd' : raw_df['BENE_SEX_IDENT_CD'], \n",
    "                          'bene_race_cd' : raw_df['BENE_RACE_CD']})\n",
    "        f['sample_number'] = re.sub('\\.','',re.findall('\\d{1}\\.', sf)[0])\n",
    "        k = pd.concat([k, f], axis = 0)\n",
    "    print(k.shape)\n",
    "    k.drop_duplicates(inplace = True)\n",
    "    print(k.shape)\n",
    "    print(k.head())\n",
    "\n",
    "    # in a loop, clean each summary data frame associated with each sample number and attach to core keys\n",
    "    rebuilt_df = pd.DataFrame()\n",
    "    for n in list(set(file_dict.values())):\n",
    "        filter_k = k.loc[k['sample_number']==n,:] # filter to dataframe for each sample number\n",
    "        \n",
    "        # iterate over the yearly summary files only relevant to the sample number n\n",
    "        for s in [f for f in list(file_dict.keys()) if file_dict[f] == n]:\n",
    "            raw_df = pd.read_csv('synthetic_data/'+ s , compression='zip')\n",
    "            raw_df['sample_number'] = re.sub('\\.','',re.findall('\\d{1}\\.', s)[0])\n",
    "            # year specific column\n",
    "            year_specific = raw_df[['SP_STATE_CODE', 'BENE_COUNTY_CD', \n",
    "                                    'BENE_DEATH_DT', 'BENE_ESRD_IND',\n",
    "                                    'BENE_HI_CVRAGE_TOT_MONS', 'BENE_SMI_CVRAGE_TOT_MONS',\n",
    "                                    'BENE_HMO_CVRAGE_TOT_MONS', 'PLAN_CVRG_MOS_NUM',\n",
    "                                    'MEDREIMB_IP', 'BENRES_IP', 'PPPYMT_IP', 'MEDREIMB_OP', 'BENRES_OP',\n",
    "                                    'PPPYMT_OP', 'MEDREIMB_CAR', 'BENRES_CAR', 'PPPYMT_CAR']]\n",
    "            year_specific.columns = [(n + '_' + re.findall('\\d{4}', s)[0]).lower() for n in year_specific]\n",
    "            year_specific['desynpuf_id'] = raw_df['DESYNPUF_ID']\n",
    "\n",
    "            chronic_condition_cols = [cc for cc in raw_df.columns if ((cc[:3] == ('SP_')) & (cc != 'SP_STATE_CODE'))]\n",
    "            #new_chronic_condition_cols = [n + '_' + re.findall('\\d{4}', s)[0] for n in chronic_condition_cols]\n",
    "            for col in chronic_condition_cols:\n",
    "                raw_df[col] = raw_df[col] - 1\n",
    "            year_specific['chronic_condition_count_'+re.findall('\\d{4}', s)[0]] = raw_df[chronic_condition_cols].sum(axis = 1)\n",
    "            print(s.upper() + ' JOINER SHAPE', year_specific.shape)\n",
    "            filter_k = filter_k.merge(year_specific, how='left', on='desynpuf_id')\n",
    "            print(s.upper() + ' NEW K SHAPE', filter_k.shape)\n",
    "                        \n",
    "        # restack each portion\n",
    "        rebuilt_df = pd.concat([rebuilt_df, filter_k], axis = 0)\n",
    "        print('NEW REBUILT DF SHAPE: ', rebuilt_df.shape)\n",
    "    \n",
    "    k = rebuilt_df.drop_duplicates()\n",
    "    print('DEDUPED REBUILT DF SHAPE: ', k.shape)\n",
    "    \n",
    "    collapsed_st = k.loc[:, [st for st in k.columns if (st[:13] == 'sp_state_code')]].apply(join_codes, axis = 1)\n",
    "    k['collapsed_states'] = collapsed_st\n",
    "\n",
    "    collapsed_ct = k.loc[:, [ct for ct in k.columns if (ct[:14] == 'bene_county_cd')]].apply(join_codes, axis = 1)\n",
    "    k['collapsed_counties'] = collapsed_ct\n",
    "\n",
    "    ## future improvement - combine columns and change to month and year died?\n",
    "    k['death_ind_2008'] = np.where(k['bene_death_dt_2008'].isnull() == False, 1, 0)\n",
    "    k['death_ind_2009'] = np.where(k['bene_death_dt_2009'].isnull() == False, 1, 0)\n",
    "    k['death_ind_2010'] = np.where(k['bene_death_dt_2010'].isnull() == False, 1, 0)\n",
    "    \n",
    "    print('df shape - model df', df.shape)\n",
    "    print('k shape - shape of keys df', k.shape)\n",
    "    print('df head - model df', df.head())\n",
    "    merged_df = df.merge(k, how='left', on=['desynpuf_id','sample_number'])\n",
    "    print('merged df shape - join k to df',merged_df.shape)\n",
    "    merged_df.drop_duplicates(inplace = True)\n",
    "    print('merged df shape without dupes', merged_df.shape)\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder with synthetic data\n",
    "parent = 'C:/Users/598300/wids/medicare-fraud/synthetic_data/'\n",
    "\n",
    "# regex pattern for file type (we are focusing on Inpatient for our analysis)\n",
    "patt = '*Inpatient_Claims_Sample_*' # regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Modeling Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DESYNPUF_ID', 'CLM_ID', 'SEGMENT', 'CLM_FROM_DT', 'CLM_THRU_DT',\n",
      "       'PRVDR_NUM', 'CLM_PMT_AMT', 'NCH_PRMRY_PYR_CLM_PD_AMT', 'AT_PHYSN_NPI',\n",
      "       'OP_PHYSN_NPI', 'OT_PHYSN_NPI', 'CLM_ADMSN_DT', 'ADMTNG_ICD9_DGNS_CD',\n",
      "       'CLM_PASS_THRU_PER_DIEM_AMT', 'NCH_BENE_IP_DDCTBL_AMT',\n",
      "       'NCH_BENE_PTA_COINSRNC_LBLTY_AM', 'NCH_BENE_BLOOD_DDCTBL_LBLTY_AM',\n",
      "       'CLM_UTLZTN_DAY_CNT', 'NCH_BENE_DSCHRG_DT', 'CLM_DRG_CD',\n",
      "       'ICD9_DGNS_CD_1', 'ICD9_DGNS_CD_2', 'ICD9_DGNS_CD_3', 'ICD9_DGNS_CD_4',\n",
      "       'ICD9_DGNS_CD_5', 'ICD9_DGNS_CD_6', 'ICD9_DGNS_CD_7', 'ICD9_DGNS_CD_8',\n",
      "       'ICD9_DGNS_CD_9', 'ICD9_DGNS_CD_10', 'ICD9_PRCDR_CD_1',\n",
      "       'ICD9_PRCDR_CD_2', 'ICD9_PRCDR_CD_3', 'ICD9_PRCDR_CD_4',\n",
      "       'ICD9_PRCDR_CD_5', 'ICD9_PRCDR_CD_6', 'HCPCS_CD_1', 'HCPCS_CD_2',\n",
      "       'HCPCS_CD_3', 'HCPCS_CD_4', 'HCPCS_CD_5', 'HCPCS_CD_6', 'HCPCS_CD_7',\n",
      "       'HCPCS_CD_8', 'HCPCS_CD_9', 'HCPCS_CD_10', 'HCPCS_CD_11', 'HCPCS_CD_12',\n",
      "       'HCPCS_CD_13', 'HCPCS_CD_14', 'HCPCS_CD_15', 'HCPCS_CD_16',\n",
      "       'HCPCS_CD_17', 'HCPCS_CD_18', 'HCPCS_CD_19', 'HCPCS_CD_20',\n",
      "       'HCPCS_CD_21', 'HCPCS_CD_22', 'HCPCS_CD_23', 'HCPCS_CD_24',\n",
      "       'HCPCS_CD_25', 'HCPCS_CD_26', 'HCPCS_CD_27', 'HCPCS_CD_28',\n",
      "       'HCPCS_CD_29', 'HCPCS_CD_30', 'HCPCS_CD_31', 'HCPCS_CD_32',\n",
      "       'HCPCS_CD_33', 'HCPCS_CD_34', 'HCPCS_CD_35', 'HCPCS_CD_36',\n",
      "       'HCPCS_CD_37', 'HCPCS_CD_38', 'HCPCS_CD_39', 'HCPCS_CD_40',\n",
      "       'HCPCS_CD_41', 'HCPCS_CD_42', 'HCPCS_CD_43', 'HCPCS_CD_44',\n",
      "       'HCPCS_CD_45', 'sample_number'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            clm_id       desynpuf_id sample_number  clm_start_year  \\\n",
      "0  196661176988405  00013D2EFD8E45D1             1            2010   \n",
      "1  196201177000368  00016F745862898F             1            2009   \n",
      "2  196661177015632  00016F745862898F             1            2009   \n",
      "3  196091176981058  00016F745862898F             1            2009   \n",
      "4  196261176983265  00016F745862898F             1            2010   \n",
      "\n",
      "   clm_start_month clm_from_datetime  clm_utlztn_day_cnt  \\\n",
      "0                3        2010-03-12                 1.0   \n",
      "1                4        2009-04-12                 6.0   \n",
      "2                8        2009-08-31                 2.0   \n",
      "3                9        2009-09-17                 3.0   \n",
      "4                6        2010-06-26                 5.0   \n",
      "\n",
      "  clm_utlztn_day_cnt_grouped prvdr_num prvdr_num_grp  at_physn_npi clm_drg_cd  \\\n",
      "0                   0-3 days    2600GD        2600gd  3.139084e+09        217   \n",
      "1                   4-7 days    3900MB        3900mb  6.476809e+09        201   \n",
      "2                   0-3 days    3900HM        3900hm  6.119985e+08        750   \n",
      "3                   0-3 days    3913XU         Other  4.971603e+09        883   \n",
      "4                   4-7 days    3900MB        3900mb  6.408400e+09        983   \n",
      "\n",
      "  clm_drg_cd_grp  clm_pmt_amt  \n",
      "0            217       4000.0  \n",
      "1            201      26000.0  \n",
      "2          Other       5000.0  \n",
      "3            883       5000.0  \n",
      "4            983      16000.0  \n",
      "icd9_dgns\n",
      "['icd9_dgns_cd_1', 'icd9_dgns_cd_2', 'icd9_dgns_cd_3', 'icd9_dgns_cd_4', 'icd9_dgns_cd_5', 'icd9_dgns_cd_6', 'icd9_dgns_cd_7', 'icd9_dgns_cd_8', 'icd9_dgns_cd_9', 'icd9_dgns_cd_10']\n",
      "icd9_pcrdr\n",
      "['icd9_prcdr_cd_1', 'icd9_prcdr_cd_2', 'icd9_prcdr_cd_3', 'icd9_prcdr_cd_4', 'icd9_prcdr_cd_5', 'icd9_prcdr_cd_6']\n",
      "hcpcs_cd\n",
      "['hcpcs_cd_1', 'hcpcs_cd_2', 'hcpcs_cd_3', 'hcpcs_cd_4', 'hcpcs_cd_5', 'hcpcs_cd_6', 'hcpcs_cd_7', 'hcpcs_cd_8', 'hcpcs_cd_9', 'hcpcs_cd_10', 'hcpcs_cd_11', 'hcpcs_cd_12', 'hcpcs_cd_13', 'hcpcs_cd_14', 'hcpcs_cd_15', 'hcpcs_cd_16', 'hcpcs_cd_17', 'hcpcs_cd_18', 'hcpcs_cd_19', 'hcpcs_cd_20', 'hcpcs_cd_21', 'hcpcs_cd_22', 'hcpcs_cd_23', 'hcpcs_cd_24', 'hcpcs_cd_25', 'hcpcs_cd_26', 'hcpcs_cd_27', 'hcpcs_cd_28', 'hcpcs_cd_29', 'hcpcs_cd_30', 'hcpcs_cd_31', 'hcpcs_cd_32', 'hcpcs_cd_33', 'hcpcs_cd_34', 'hcpcs_cd_35', 'hcpcs_cd_36', 'hcpcs_cd_37', 'hcpcs_cd_38', 'hcpcs_cd_39', 'hcpcs_cd_40', 'hcpcs_cd_41', 'hcpcs_cd_42', 'hcpcs_cd_43', 'hcpcs_cd_44', 'hcpcs_cd_45']\n",
      "physn_npi\n",
      "['at_physn_npi', 'op_physn_npi', 'ot_physn_npi']\n",
      "{'DE1_0_2008_Beneficiary_Summary_File_Sample_1.zip': '1', 'DE1_0_2008_Beneficiary_Summary_File_Sample_2.zip': '2', 'DE1_0_2009_Beneficiary_Summary_File_Sample_1.zip': '1', 'DE1_0_2009_Beneficiary_Summary_File_Sample_2.zip': '2', 'DE1_0_2010_Beneficiary_Summary_File_Sample_1.zip': '1', 'DE1_0_2010_Beneficiary_Summary_File_Sample_2.zip': '2'}\n",
      "(687502, 5)\n",
      "(232747, 5)\n",
      "        desynpuf_id bene_birth_dt bene_sex_ident_cd bene_race_cd sample_number\n",
      "0  00013D2EFD8E45D1      19230501                 1            1             1\n",
      "1  00016F745862898F      19430101                 1            1             1\n",
      "2  0001FDD721E223DC      19360901                 2            1             1\n",
      "3  00021CA6FF03E670      19410601                 1            5             1\n",
      "4  00024B3D2352D2D0      19360801                 1            1             1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DE1_0_2008_BENEFICIARY_SUMMARY_FILE_SAMPLE_2.ZIP JOINER SHAPE (116395, 19)\n",
      "DE1_0_2008_BENEFICIARY_SUMMARY_FILE_SAMPLE_2.ZIP NEW K SHAPE (116395, 23)\n",
      "DE1_0_2009_BENEFICIARY_SUMMARY_FILE_SAMPLE_2.ZIP JOINER SHAPE (114618, 19)\n",
      "DE1_0_2009_BENEFICIARY_SUMMARY_FILE_SAMPLE_2.ZIP NEW K SHAPE (116395, 41)\n",
      "DE1_0_2010_BENEFICIARY_SUMMARY_FILE_SAMPLE_2.ZIP JOINER SHAPE (112845, 19)\n",
      "DE1_0_2010_BENEFICIARY_SUMMARY_FILE_SAMPLE_2.ZIP NEW K SHAPE (116395, 59)\n",
      "NEW REBUILT DF SHAPE:  (116395, 59)\n",
      "DE1_0_2008_BENEFICIARY_SUMMARY_FILE_SAMPLE_1.ZIP JOINER SHAPE (116352, 19)\n",
      "DE1_0_2008_BENEFICIARY_SUMMARY_FILE_SAMPLE_1.ZIP NEW K SHAPE (116352, 23)\n",
      "DE1_0_2009_BENEFICIARY_SUMMARY_FILE_SAMPLE_1.ZIP JOINER SHAPE (114538, 19)\n",
      "DE1_0_2009_BENEFICIARY_SUMMARY_FILE_SAMPLE_1.ZIP NEW K SHAPE (116352, 41)\n",
      "DE1_0_2010_BENEFICIARY_SUMMARY_FILE_SAMPLE_1.ZIP JOINER SHAPE (112754, 19)\n",
      "DE1_0_2010_BENEFICIARY_SUMMARY_FILE_SAMPLE_1.ZIP NEW K SHAPE (116352, 59)\n",
      "NEW REBUILT DF SHAPE:  (232747, 59)\n",
      "DEDUPED REBUILT DF SHAPE:  (232747, 59)\n",
      "df shape - model df (133139, 20)\n",
      "k shape - shape of keys df (232747, 64)\n",
      "df head - model df             clm_id       desynpuf_id sample_number  clm_start_year  \\\n",
      "0  196661176988405  00013D2EFD8E45D1             1            2010   \n",
      "1  196201177000368  00016F745862898F             1            2009   \n",
      "2  196661177015632  00016F745862898F             1            2009   \n",
      "3  196091176981058  00016F745862898F             1            2009   \n",
      "4  196261176983265  00016F745862898F             1            2010   \n",
      "\n",
      "   clm_start_month clm_from_datetime  clm_utlztn_day_cnt  \\\n",
      "0                3        2010-03-12                 1.0   \n",
      "1                4        2009-04-12                 6.0   \n",
      "2                8        2009-08-31                 2.0   \n",
      "3                9        2009-09-17                 3.0   \n",
      "4                6        2010-06-26                 5.0   \n",
      "\n",
      "  clm_utlztn_day_cnt_grouped prvdr_num prvdr_num_grp  at_physn_npi clm_drg_cd  \\\n",
      "0                   0-3 days    2600GD        2600gd  3.139084e+09        217   \n",
      "1                   4-7 days    3900MB        3900mb  6.476809e+09        201   \n",
      "2                   0-3 days    3900HM        3900hm  6.119985e+08        750   \n",
      "3                   0-3 days    3913XU         Other  4.971603e+09        883   \n",
      "4                   4-7 days    3900MB        3900mb  6.408400e+09        983   \n",
      "\n",
      "  clm_drg_cd_grp  clm_pmt_amt  \\\n",
      "0            217       4000.0   \n",
      "1            201      26000.0   \n",
      "2          Other       5000.0   \n",
      "3            883       5000.0   \n",
      "4            983      16000.0   \n",
      "\n",
      "                                 collapsed_icd9_dgns collapsed_icd9_pcrdr  \\\n",
      "0  7802 78820 E9330 V4502 73300 2720 4280 4019 V4501                        \n",
      "1     71590 2724 2768 7843 19889 5853 1970 5849 4019                        \n",
      "2                                    56400 2948 6186    V5866 7092.0 6186   \n",
      "3                V1581 71690 34590 32723 30390 29623                        \n",
      "4     2639 V8801 7840 3569 78820 4271 7856 3542 4019                E8889   \n",
      "\n",
      "  collapsed_hcpcs_cd        collapsed_physn_npi  \\\n",
      "0                                  3139083564.0   \n",
      "1                                  6476809087.0   \n",
      "2                                   611998537.0   \n",
      "3                     4971602784.0 1119000316.0   \n",
      "4                     1960859579.0 6408400473.0   \n",
      "\n",
      "             collapsed_icd9_dgns_group collapsed_icd9_prcdr_group  \n",
      "0      E93 733 401 272 428 788 V45 780                             \n",
      "1  584 198 401 272 276 715 197 784 585                             \n",
      "2                          564 294 618                V58 618 709  \n",
      "3              716 296 V15 303 345 327                             \n",
      "4  401 V88 263 788 356 427 784 354 785                        E88  \n",
      "merged df shape - join k to df (133139, 82)\n",
      "merged df shape without dupes (133139, 82)\n"
     ]
    }
   ],
   "source": [
    "# read files for inpatient\n",
    "df = read_in_all_files(parent, patt)\n",
    "# create core dataframe\n",
    "model_df = create_inpatient_core_df(df)\n",
    "# attach yearly summary information\n",
    "model_df = add_summary_info(model_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133267, 82)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desynpuf_id</th>\n",
       "      <th>clm_id</th>\n",
       "      <th>segment</th>\n",
       "      <th>clm_from_dt</th>\n",
       "      <th>clm_thru_dt</th>\n",
       "      <th>prvdr_num</th>\n",
       "      <th>clm_pmt_amt</th>\n",
       "      <th>nch_prmry_pyr_clm_pd_amt</th>\n",
       "      <th>at_physn_npi</th>\n",
       "      <th>op_physn_npi</th>\n",
       "      <th>...</th>\n",
       "      <th>hcpcs_cd_37</th>\n",
       "      <th>hcpcs_cd_38</th>\n",
       "      <th>hcpcs_cd_39</th>\n",
       "      <th>hcpcs_cd_40</th>\n",
       "      <th>hcpcs_cd_41</th>\n",
       "      <th>hcpcs_cd_42</th>\n",
       "      <th>hcpcs_cd_43</th>\n",
       "      <th>hcpcs_cd_44</th>\n",
       "      <th>hcpcs_cd_45</th>\n",
       "      <th>sample_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00013D2EFD8E45D1</td>\n",
       "      <td>196661176988405</td>\n",
       "      <td>1</td>\n",
       "      <td>20100312.0</td>\n",
       "      <td>20100313.0</td>\n",
       "      <td>2600GD</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.139084e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016F745862898F</td>\n",
       "      <td>196201177000368</td>\n",
       "      <td>1</td>\n",
       "      <td>20090412.0</td>\n",
       "      <td>20090418.0</td>\n",
       "      <td>3900MB</td>\n",
       "      <td>26000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.476809e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016F745862898F</td>\n",
       "      <td>196661177015632</td>\n",
       "      <td>1</td>\n",
       "      <td>20090831.0</td>\n",
       "      <td>20090902.0</td>\n",
       "      <td>3900HM</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.119985e+08</td>\n",
       "      <td>6.119985e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016F745862898F</td>\n",
       "      <td>196091176981058</td>\n",
       "      <td>1</td>\n",
       "      <td>20090917.0</td>\n",
       "      <td>20090920.0</td>\n",
       "      <td>3913XU</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.971603e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016F745862898F</td>\n",
       "      <td>196261176983265</td>\n",
       "      <td>1</td>\n",
       "      <td>20100626.0</td>\n",
       "      <td>20100701.0</td>\n",
       "      <td>3900MB</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.408400e+09</td>\n",
       "      <td>1.960860e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        desynpuf_id           clm_id  segment  clm_from_dt  clm_thru_dt  \\\n",
       "0  00013D2EFD8E45D1  196661176988405        1   20100312.0   20100313.0   \n",
       "1  00016F745862898F  196201177000368        1   20090412.0   20090418.0   \n",
       "2  00016F745862898F  196661177015632        1   20090831.0   20090902.0   \n",
       "3  00016F745862898F  196091176981058        1   20090917.0   20090920.0   \n",
       "4  00016F745862898F  196261176983265        1   20100626.0   20100701.0   \n",
       "\n",
       "  prvdr_num  clm_pmt_amt  nch_prmry_pyr_clm_pd_amt  at_physn_npi  \\\n",
       "0    2600GD       4000.0                       0.0  3.139084e+09   \n",
       "1    3900MB      26000.0                       0.0  6.476809e+09   \n",
       "2    3900HM       5000.0                       0.0  6.119985e+08   \n",
       "3    3913XU       5000.0                       0.0  4.971603e+09   \n",
       "4    3900MB      16000.0                       0.0  6.408400e+09   \n",
       "\n",
       "   op_physn_npi      ...       hcpcs_cd_37  hcpcs_cd_38 hcpcs_cd_39  \\\n",
       "0           NaN      ...               NaN          NaN         NaN   \n",
       "1           NaN      ...               NaN          NaN         NaN   \n",
       "2  6.119985e+08      ...               NaN          NaN         NaN   \n",
       "3           NaN      ...               NaN          NaN         NaN   \n",
       "4  1.960860e+09      ...               NaN          NaN         NaN   \n",
       "\n",
       "   hcpcs_cd_40  hcpcs_cd_41  hcpcs_cd_42  hcpcs_cd_43  hcpcs_cd_44  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "1          NaN          NaN          NaN          NaN          NaN   \n",
       "2          NaN          NaN          NaN          NaN          NaN   \n",
       "3          NaN          NaN          NaN          NaN          NaN   \n",
       "4          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   hcpcs_cd_45 sample_number  \n",
       "0          NaN             1  \n",
       "1          NaN             1  \n",
       "2          NaN             1  \n",
       "3          NaN             1  \n",
       "4          NaN             1  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133139, 82)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clm_id</th>\n",
       "      <th>desynpuf_id</th>\n",
       "      <th>sample_number</th>\n",
       "      <th>clm_start_year</th>\n",
       "      <th>clm_start_month</th>\n",
       "      <th>clm_from_datetime</th>\n",
       "      <th>clm_utlztn_day_cnt</th>\n",
       "      <th>clm_utlztn_day_cnt_grouped</th>\n",
       "      <th>prvdr_num</th>\n",
       "      <th>prvdr_num_grp</th>\n",
       "      <th>...</th>\n",
       "      <th>pppymt_op_2010</th>\n",
       "      <th>medreimb_car_2010</th>\n",
       "      <th>benres_car_2010</th>\n",
       "      <th>pppymt_car_2010</th>\n",
       "      <th>chronic_condition_count_2010</th>\n",
       "      <th>collapsed_states</th>\n",
       "      <th>collapsed_counties</th>\n",
       "      <th>death_ind_2008</th>\n",
       "      <th>death_ind_2009</th>\n",
       "      <th>death_ind_2010</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196661176988405</td>\n",
       "      <td>00013D2EFD8E45D1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-03-12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0-3 days</td>\n",
       "      <td>2600GD</td>\n",
       "      <td>2600gd</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>196201177000368</td>\n",
       "      <td>00016F745862898F</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>2009-04-12</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4-7 days</td>\n",
       "      <td>3900MB</td>\n",
       "      <td>3900mb</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>930.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>196661177015632</td>\n",
       "      <td>00016F745862898F</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>2009-08-31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0-3 days</td>\n",
       "      <td>3900HM</td>\n",
       "      <td>3900hm</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>930.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196091176981058</td>\n",
       "      <td>00016F745862898F</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>2009-09-17</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0-3 days</td>\n",
       "      <td>3913XU</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>930.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>196261176983265</td>\n",
       "      <td>00016F745862898F</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-06-26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4-7 days</td>\n",
       "      <td>3900MB</td>\n",
       "      <td>3900mb</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>930.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            clm_id       desynpuf_id sample_number  clm_start_year  \\\n",
       "0  196661176988405  00013D2EFD8E45D1             1            2010   \n",
       "1  196201177000368  00016F745862898F             1            2009   \n",
       "2  196661177015632  00016F745862898F             1            2009   \n",
       "3  196091176981058  00016F745862898F             1            2009   \n",
       "4  196261176983265  00016F745862898F             1            2010   \n",
       "\n",
       "   clm_start_month clm_from_datetime  clm_utlztn_day_cnt  \\\n",
       "0                3        2010-03-12                 1.0   \n",
       "1                4        2009-04-12                 6.0   \n",
       "2                8        2009-08-31                 2.0   \n",
       "3                9        2009-09-17                 3.0   \n",
       "4                6        2010-06-26                 5.0   \n",
       "\n",
       "  clm_utlztn_day_cnt_grouped prvdr_num prvdr_num_grp      ...        \\\n",
       "0                   0-3 days    2600GD        2600gd      ...         \n",
       "1                   4-7 days    3900MB        3900mb      ...         \n",
       "2                   0-3 days    3900HM        3900hm      ...         \n",
       "3                   0-3 days    3913XU         Other      ...         \n",
       "4                   4-7 days    3900MB        3900mb      ...         \n",
       "\n",
       "   pppymt_op_2010 medreimb_car_2010 benres_car_2010  pppymt_car_2010  \\\n",
       "0             0.0              90.0            30.0              0.0   \n",
       "1             0.0             930.0           150.0              0.0   \n",
       "2             0.0             930.0           150.0              0.0   \n",
       "3             0.0             930.0           150.0              0.0   \n",
       "4             0.0             930.0           150.0              0.0   \n",
       "\n",
       "  chronic_condition_count_2010 collapsed_states collapsed_counties  \\\n",
       "0                          9.0             26.0              950.0   \n",
       "1                          7.0             39.0              230.0   \n",
       "2                          7.0             39.0              230.0   \n",
       "3                          7.0             39.0              230.0   \n",
       "4                          7.0             39.0              230.0   \n",
       "\n",
       "  death_ind_2008 death_ind_2009 death_ind_2010  \n",
       "0              0              0              0  \n",
       "1              0              0              0  \n",
       "2              0              0              0  \n",
       "3              0              0              0  \n",
       "4              0              0              0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model_df.shape)\n",
    "model_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
